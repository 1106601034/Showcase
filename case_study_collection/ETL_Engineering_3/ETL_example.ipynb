{"cells":[{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":298,"status":"ok","timestamp":1694236477947,"user":{"displayName":"Christopher Chan","userId":"17264957305028452462"},"user_tz":-600},"id":"inK3ZvwpJ0Ch"},"outputs":[],"source":["import glob                         # this module helps in selecting files\n","import pandas as pd                 # this module helps in processing CSV files\n","import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n","from datetime import datetime"]},{"cell_type":"markdown","metadata":{"id":"hZlMgGchJ0Ck"},"source":["## Download Files\n"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1694236478708,"user":{"displayName":"Christopher Chan","userId":"17264957305028452462"},"user_tz":-600},"id":"2owTd3IDJ0Cm","outputId":"73d6ca5a-3546-4b0f-d20d-80cb2b56bc76"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-09-09 05:14:38--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\n","Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\n","Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2707 (2.6K) [application/zip]\n","Saving to: ‘source.zip.1’\n","\n","source.zip.1        100%[===================\u003e]   2.64K  --.-KB/s    in 0s      \n","\n","2023-09-09 05:14:38 (1.17 GB/s) - ‘source.zip.1’ saved [2707/2707]\n","\n"]}],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip"]},{"cell_type":"markdown","metadata":{"id":"fORZph5JJ0Co"},"source":["## Unzip Files\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"0aKn109YJ0Cq"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  source.zip\n","replace source3.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["!unzip source.zip"]},{"cell_type":"markdown","metadata":{"id":"GdxPZPUTJ0Ct"},"source":["## Set Paths\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-LAkzjtJ0Cv"},"outputs":[],"source":["tmpfile    = \"temp.tmp\"               # file used to store all extracted data\n","logfile    = \"logfile.txt\"            # all event logs will be stored in this file\n","targetfile = \"transformed_data.csv\"   # file where transformed data is stored"]},{"cell_type":"markdown","metadata":{"id":"BE2cUUS0J0Cx"},"source":["## Extract\n"]},{"cell_type":"markdown","metadata":{"id":"Vb3ItgYLJ0Cz"},"source":["### CSV Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KZFYe8e2J0C0"},"outputs":[],"source":["def extract_from_csv(file_to_process):\n","    dataframe = pd.read_csv(file_to_process)\n","    return dataframe"]},{"cell_type":"markdown","metadata":{"id":"QvBQYxMcJ0C2"},"source":["### JSON Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IeAFMuhNJ0C3"},"outputs":[],"source":["def extract_from_json(file_to_process):\n","    dataframe = pd.read_json(file_to_process,lines=True)\n","    return dataframe"]},{"cell_type":"markdown","metadata":{"id":"gP-ymhkzJ0C5"},"source":["### XML Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3DbwodGFJ0C6"},"outputs":[],"source":["def extract_from_xml(file_to_process):\n","    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n","    tree = ET.parse(file_to_process)\n","    root = tree.getroot()\n","    for person in root:\n","        name = person.find(\"name\").text\n","        height = float(person.find(\"height\").text)\n","        weight = float(person.find(\"weight\").text)\n","        dataframe = dataframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n","    return dataframe"]},{"cell_type":"markdown","metadata":{"id":"b5sGH0JYJ0C8"},"source":["### Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfZU36h5J0DA"},"outputs":[],"source":["def extract():\n","    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n","\n","    #process all csv files\n","    for csvfile in glob.glob(\"*.csv\"):\n","        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n","\n","    #process all json files\n","    for jsonfile in glob.glob(\"*.json\"):\n","        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n","\n","    #process all xml files\n","    for xmlfile in glob.glob(\"*.xml\"):\n","        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n","\n","    return extracted_data"]},{"cell_type":"markdown","metadata":{"id":"xmwsNZfDJ0DC"},"source":["## Transform\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2OgN21pJ0DE"},"outputs":[],"source":["def transform(data):\n","        #Convert height which is in inches to millimeter\n","        #Convert the datatype of the column into float\n","        #data.height = data.height.astype(float)\n","        #Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)\n","        data['height'] = round(data.height * 0.0254,2)\n","\n","        #Convert weight which is in pounds to kilograms\n","        #Convert the datatype of the column into float\n","        #data.weight = data.weight.astype(float)\n","        #Convert pounds to kilograms and round off to two decimals(one pound is 0.45359237 kilograms)\n","        data['weight'] = round(data.weight * 0.45359237,2)\n","        return data"]},{"cell_type":"markdown","metadata":{"id":"1NcRgYqcJ0DG"},"source":["## Loading\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZvqiZpdxJ0DH"},"outputs":[],"source":["def load(targetfile,data_to_load):\n","    data_to_load.to_csv(targetfile)"]},{"cell_type":"markdown","metadata":{"id":"rkXGnaoaJ0DI"},"source":["## Logging\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ce1yX803J0DI"},"outputs":[],"source":["def log(message):\n","    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n","    now = datetime.now() # get current timestamp\n","    timestamp = now.strftime(timestamp_format)\n","    with open(\"logfile.txt\",\"a\") as f:\n","        f.write(timestamp + ',' + message + '\\n')"]},{"cell_type":"markdown","metadata":{"id":"Ytyp4_CWJ0DI"},"source":["## Running ETL Process\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nmJza4NlJ0DJ"},"outputs":[],"source":["log(\"ETL Job Started\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vHHfiEHOJ0DJ"},"outputs":[],"source":["log(\"Extract phase Started\")\n","extracted_data = extract()\n","log(\"Extract phase Ended\")\n","extracted_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GbV2EN9xJ0DK"},"outputs":[],"source":["log(\"Transform phase Started\")\n","transformed_data = transform(extracted_data)\n","log(\"Transform phase Ended\")\n","transformed_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hBLasvOSJ0DL"},"outputs":[],"source":["log(\"Load phase Started\")\n","load(targetfile,transformed_data)\n","log(\"Load phase Ended\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQnqXS1wJ0DL"},"outputs":[],"source":["log(\"ETL Job Ended\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8i-W3CBr2Ye"},"outputs":[],"source":["with open(\"logfile.txt\", \"r\") as f: # check the logfile\n","  print(f.read())"]},{"cell_type":"markdown","metadata":{"id":"fRJUBbKpJ0DM"},"source":["# Exercise\n"]},{"cell_type":"markdown","metadata":{"id":"2H0W8TcBJ0DM"},"source":["## Download Files\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MjCNr5WJ0DN"},"outputs":[],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip"]},{"cell_type":"markdown","metadata":{"id":"X2klxSYdJ0DN"},"source":["## Unzip Files\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkCQ3gSxJ0DO"},"outputs":[],"source":["!unzip datasource.zip -d dealership_data"]},{"cell_type":"markdown","metadata":{"id":"J_5am1hKJ0DP"},"source":["## About the Data\n"]},{"cell_type":"markdown","metadata":{"id":"OChizee7J0DP"},"source":["The file `dealership_data` contains CSV, JSON, and XML files for used car data which contain features named `car_model`, `year_of_manufacture`, `price`, and `fuel`.\n"]},{"cell_type":"markdown","metadata":{"id":"UC2ggP3gJ0DP"},"source":["## Set Paths\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugQaMRpUJ0DQ"},"outputs":[],"source":["tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\n","logfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\n","targetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored"]},{"cell_type":"markdown","metadata":{"id":"tbeO3zgxJ0DQ"},"source":["## Extract\n"]},{"cell_type":"markdown","metadata":{"id":"g_PED20XJ0DR"},"source":["### Question 1: CSV Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCleOr-IJ0DR"},"outputs":[],"source":["def csv_extract(file):\n","  dataframe = pd.read_csv(file)\n","  return dataframe"]},{"cell_type":"markdown","metadata":{"id":"_sgLxxKEJ0DS"},"source":["### Question 2: JSON Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie0wVSyyJ0DS"},"outputs":[],"source":["def json_extract(file):\n","  dataframe = pd.read_json(file, lines = True)\n","  return dataframe"]},{"cell_type":"markdown","metadata":{"id":"mmTWzATsJ0DT"},"source":["### Question 3: XML Extract Function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctsuHDPrJ0DT"},"outputs":[],"source":["def xml_extract(file, feature_names):\n","  dataframe = pd.Dataframe(columns = feature_names)\n","  tree = ET.parse(file)\n","  root = tree.getroot()\n","  for each_root in root:\n","    for each_feature in len(feature_names):\n","      if isinstance(each_feature, int) is True:\n","        feature_names[each_feature] = int(each_root.find(feature_names[each_feature]).text) # if the value is int then int()\n","      elif isinstance(each_feature, float) is True:\n","        feature_names[each_feature] = float(each_root.find(feature_names[each_feature]).text) # if the value is float then float()\n","      else:\n","        feature_names[each_feature] = each_root.find(feature_names[each_feature]).text # otherwise just string"]},{"cell_type":"markdown","metadata":{"id":"xvE0v2yxJ0DV"},"source":["### Question 4: Extract Function\n","\n","Call the specific extract functions you created above by replacing the `ADD_FUNCTION_CALL` with the proper function call.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UyuIcAYJ0DV"},"outputs":[],"source":["def extract():\n","    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n","\n","    #process all csv files\n","    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n","        extracted_data = extracted_data.append(csv_extract(csvfile), ignore_index=True)\n","\n","    #process all json files\n","    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n","        extracted_data = extracted_data.append(json_extract(jsonfile), ignore_index=True)\n","\n","    #process all xml files\n","    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n","        extracted_data = extracted_data.append(xml_extract(xmlfile, extracted_data.columns), ignore_index=True)\n","\n","    return extracted_data"]},{"cell_type":"markdown","metadata":{"id":"B5LPJ8y2J0DW"},"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","    \n","```\n","    \n","def extract():\n","    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n","    \n","    #process all csv files\n","    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n","        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n","        \n","    #process all json files\n","    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n","        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n","    \n","    #process all xml files\n","    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n","        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n","        \n","    return extracted_data\n","```\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","metadata":{"id":"HDcbYmBhJ0DW"},"source":["## Transform\n"]},{"cell_type":"markdown","metadata":{"id":"VNdoPr_fJ0DW"},"source":["### Question 5: Transform\n","\n","Round the `price` columns to 2 decimal places\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywzFdMJyJ0DX"},"outputs":[],"source":["def transform(data):\n","  data['price'] = round(data.price, 2)\n","  return data"]},{"cell_type":"markdown","metadata":{"id":"Y752Gw-ZJ0DX"},"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","    \n","```\n","\n","def transform(data):\n","        data['price'] = round(data.price, 2)\n","        return data\n","```\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","metadata":{"id":"l4n3lzSoJ0DY"},"source":["## Loading\n"]},{"cell_type":"markdown","metadata":{"id":"Atgrl0QYJ0DY"},"source":["### Question 6: Load\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RUUM3jAOJ0DZ"},"outputs":[],"source":["def load(file, dataframe):\n","    dataframe.to_csv(file)"]},{"cell_type":"markdown","metadata":{"id":"7wKZcpyuJ0DZ"},"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","    \n","```\n","\n","def load(targetfile,data_to_load):\n","    data_to_load.to_csv(targetfile)  \n","```\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","metadata":{"id":"5jZAyk3ZJ0Da"},"source":["## Logging\n"]},{"cell_type":"markdown","metadata":{"id":"UOcUeuvXJ0Da"},"source":["### Question 7: Log\n","\n","Make sure to change the name of the logfile to the one specified in the set paths section. Change the timestamp order to Hour-Minute-Second-Monthname-Day-Year.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_g8buBTiJ0Db"},"outputs":[],"source":["def log(message):\n","  timestamp_format = '%H:%M:%S-%h-%d-%Y'\n","  now = datetime.now()\n","  timestamp = now.strftime(timestamp_format)\n","  with open(\"dealership_logfile.txt\", \"a\") as f:\n","    f.write(timestamp + ', '+message+'\\n')"]},{"cell_type":"markdown","metadata":{"id":"azfC7VH5J0Dc"},"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","    \n","```\n","\n","def log(message):\n","    timestamp_format = '%H:%M:%S-%h-%d-%Y' #Hour-Minute-Second-MonthName-Day-Year\n","    now = datetime.now() # get current timestamp\n","    timestamp = now.strftime(timestamp_format)\n","    with open(\"dealership_logfile.txt\",\"a\") as f:\n","        f.write(timestamp + ',' + message + '\\n')\n","```\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","metadata":{"id":"p1ol8R29J0Dc"},"source":["## Running ETL Process\n"]},{"cell_type":"markdown","metadata":{"id":"0AAFuW2LJ0Dd"},"source":["### Question 8: ETL Process\n","\n","Run all functions to extract, transform, and load the data. Make sure to log all events using the `log` function. Place your code under each comment.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MKthrRG6J0De"},"outputs":[],"source":["log(\"ETL Job Started\")\n","\n","log(\"Extract phase Started\")\n","extracted_data = extract()\n","log(\"Extract phase Ended\")\n","\n","log(\"Transform phase Started\")\n","transformed_data = transform(extracted_data)\n","log(\"Transform phase Ended\")\n","\n","log(\"Load phase Started\")\n","load(targetfile,transformed_data)\n","log(\"Load phase Ended\")\n","\n","log(\"ETL Job Ended\")"]},{"cell_type":"markdown","metadata":{"id":"weOgZUs1J0De"},"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","    \n","```\n","\n","log(\"ETL Job Started\")\n","\n","log(\"Extract phase Started\")\n","extracted_data = extract()\n","log(\"Extract phase Ended\")\n","\n","log(\"Transform phase Started\")\n","transformed_data = transform(extracted_data)\n","log(\"Transform phase Ended\")\n","\n","log(\"Load phase Started\")\n","load(targetfile,transformed_data)\n","log(\"Load phase Ended\")\n","\n","log(\"ETL Job Ended\")\n","```\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","metadata":{"id":"MGP-YjylJ0Df"},"source":["## Authors\n"]},{"cell_type":"markdown","metadata":{"id":"t2c5Wk0UJ0Dg"},"source":["Ramesh Sannareddy\n","\n","Joseph Santarcangelo\n","\n","Azim Hirjani\n"]},{"cell_type":"markdown","metadata":{"id":"xr1PJV1pJ0Dh"},"source":["## Change Log\n"]},{"cell_type":"markdown","metadata":{"id":"L3qqm7VCJ0Di"},"source":["| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n","| ----------------- | ------- | ----------------- | ---------------------------------- |\n","| 2020-11-25        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"]},{"cell_type":"markdown","metadata":{"id":"7w8fxs8HJ0Dj"},"source":[" Copyright © 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0221ENSkillsNetwork899-2023-01-01\u0026cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork-23455645\u0026cm_mmca1=000026UJ\u0026cm_mmca2=10006555\u0026cm_mmca3=M12345678\u0026cvosrc=email.Newsletter.M12345678\u0026cvo_campaign=000026UJ).\n"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":0}